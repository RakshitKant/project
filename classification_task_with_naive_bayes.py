# -*- coding: utf-8 -*-
"""Classification task with Naive Bayes

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eb7auwwXcOoBqKr3DyMXBhTYkZX_MH8S
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
path='/content/drive/My Drive/dataset/Clothing Reviews.csv'
df=pd.read_csv(path)

df.head()

df.columns

df.drop(["Clothing ID", "Title"], axis=1, inplace=True)
df.head()

df.isnull().sum()

len(df)

df.describe()

df['Age'].unique()

df['Class Name'].unique()

df['Recommended IND'].unique()

df['Division Name'].unique()

df['Division Name'].unique()

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns

# %matplotlib inline

"""# Sentiment Analysis"""

import string
string.punctuation

df.dtypes

df['Review Text'].head()

df['Review Text'].dtypes

"""Removing the rows that has null values"""

df = df[~df['Review Text'].isnull()]

df['length']=df['Review Text'].apply(len)

df.head()

"""Length after removing the rows where Review Text is null"""

len(df)

plt.figure(figsize=(10,8))
sns.boxplot(x='Recommended IND',y='length',data=df,hue='Rating',palette='rainbow')
plt.title('message length')

df.length.describe()

"""maximum length is 508."""

df[df['length'] == 508]['Review Text'].iloc[0]

"""**Removing puntuations**"""

import string
string.punctuation
def remove_punctuation(text):
    no_punct=[words for words in text if words not in string.punctuation]
    words_wo_punct=''.join(no_punct)
    return words_wo_punct
df['Review Text']=df['Review Text'].apply(lambda x: remove_punctuation(x))
df.head()

"""**Text blob for polarity**"""

from textblob import TextBlob
df.head()

df["Polarity"] = df["Review Text"].apply(lambda x: TextBlob(x).sentiment.polarity)

df.head()

df['Polarity'].min()

def getAnalysis(polarity):
  if polarity < 0:
    return 'Negative'
  elif polarity == 0:
    return 'Neutral'
  else:
    return 'Positive'

df['TextBlob_Analysis']=df['Polarity'].apply(getAnalysis)

df.head()

polarity_plot=df['TextBlob_Analysis'].value_counts()

polarity_plot

positive= 21213/len(df)*100
negative= 1333/len(df)*100
neutral= 95/len(df)*100

labels = ['Positive', 'Negative', 'Neutral']
sizes = [positive, negative, neutral]
plt.figure(figsize=(12,7))
plt.pie(sizes, labels=labels,autopct='%1.1f%%',shadow=True, startangle=140)
plt.show()

"""***Label Encoding***"""

#Import label encoder
from sklearn import preprocessing

# label_encoder object knows how to understand word labels.
label_encoder = preprocessing.LabelEncoder()

# Encode labels in column 'species'.
df['Encoded_value']= label_encoder.fit_transform(df['TextBlob_Analysis'])

df['Encoded_value'].unique()

df.head()

sns.boxplot(x="Rating", y="length", data=df,)

sns.boxplot(x="Encoded_value", y="length", data=df,)

"""# ***NLP Classification Task***

# Bag Of Words
"""

df['TextBlob_Analysis']=df['TextBlob_Analysis'].astype(str)

df['Polarity'].dtypes

df['Polarity'] = df['Polarity'].astype(str)

df['Review Text'] = df['Review Text'].astype(str)

"""**Cleaning the texts in 'Review Text' column and creating a corpus.**"""

import re
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
#from tqdm import tqdm
df.index = np.arange(len(df))
corpus = []
for i in range(len(df)):
  review = re.sub('[^a-zA-Z]', ' ', df['Review Text'][i])
  review = review.lower()
  review = review.split()
  ps = PorterStemmer()
  all_stopwords = stopwords.words('english')
  all_stopwords.remove('not')
  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]
  review = ' '.join(review)
  corpus.append(review)

print(corpus)

"""#vectorization

**In order to fit the corpus in count vectorizer, we need to change into the corpus to array**
"""

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer()
X = cv.fit_transform(corpus).toarray()
y = df.iloc[:, -1].values

print(y)

"""**Splitting the dataset into the Training set and Test set**

"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)

"""**Training a Model**

**Using Multinomial Naive Bayes**
"""

from sklearn.naive_bayes import MultinomialNB
nb = MultinomialNB()

"""**Fitting the train and text data in the Multinomial MB**"""

nb.fit(X_train,y_train)

"""**Predictions and Evaluations**"""

predictions = nb.predict(X_test)

"""**Create a confusion matrix and classification report using these predictions and y_test**


"""

from sklearn.metrics import confusion_matrix,classification_report
from sklearn.metrics import accuracy_score
from sklearn import metrics
acc = accuracy_score(y_test,predictions)

print("Accuracy of the classifier: ",acc)
print("Confusion matrix is :\n",metrics.confusion_matrix(y_test,predictions))
print("Classification report: \n" ,metrics.classification_report(y_test,predictions))

"""**The accuracy with Multinomial NB is 0.93**

#**Using Text Processing**

***Tfidf term frequency inverse document frequency***

TF-IDF stands for term frequency-inverse document frequency, and the tf-idf weight is a weight often used in information retrieval and text mining. This weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus. The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus.

TF: Term Frequency, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization:

IDF: Inverse Document Frequency, which measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as "is", "of", and "that", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following:

IDF(t) = log_e(Total number of documents / Number of documents with term t in it).

#**Using the Pipeline**
"""

from sklearn.pipeline import Pipeline

pipeline = Pipeline([
    ('bow', CountVectorizer()),  # strings to token integer counts
    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores
    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier
])

X = df['Review Text']
y = df['Encoded_value']
X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=101)

pipeline.fit(X_train,y_train)

"""**Predictions and Evaluation**"""

predictions = pipeline.predict(X_test)

print("Confusion matrix is :\n",metrics.confusion_matrix(y_test,predictions))
print("Classification report: \n" ,metrics.classification_report(y_test,predictions))

"""**The accuracy using pipeline method is 0.94**"""